{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Data University - Accidentologie à vélo\n",
    "\n",
    "Dans le cadre de l'opportunité Open Data University offert par *Latitudes*, nous nous sommes proposés pour un projet de *data visualization* autour de la problematiques de l'accidentologie à vélo pour apporté notre pierre à l'édifice parmis les grandes restructuration de la mobilité en France.  \n",
    "\n",
    "## SPRINT 01 - DATA CLEANING\n",
    "\n",
    "Qui dit *data visualization* dit *data*.  \n",
    "Nous avons donc trouver après recherche sur *www.data.gouv.fr* [les bases de données annuelles des accidents corporels de la circulation routière](https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2021/), un ensemble de données qui donne notamment les accidents en vélo et en VAE (Vélo à Assistance Electrique). Cependant le dataset couvre un scope plus grand que notre sujet puisqu'il se porte sur l'intégralité des accidents de la circulation routière. Il nous faut donc tout d'abord procéder à un nettoyage de la donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de 2005, la notation des accidents est séparée entre 4 fichiers: Caractéristiques, Lieux, Véhicules, Usagers.  \n",
    "Et C'est à partir du fichier Véhicules que nous allons donc pouvoir sélectionner les accidents impliquant seulement des vélo ou VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas to download, read and filter .csv files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the filepath to the .json file that contains all the dataset urls\n",
    "url_fp: str = \"data/metadata/urls.json\"\n",
    "\n",
    "# convert metadata file to dataframe which\n",
    "url_df: pd.DataFrame = pd.read_json(url_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On télécharge depuis les urls le fichier qui donne les caractéristiques des véhicules dans les accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the .csv vehicles file from url dataframe\n",
    "vehicles_url: str = url_df.at[0, 'véhicules']\n",
    "\"\"\"\n",
    "    Only use those columns because\n",
    "    we only want to extract the accident id from the vehicule category\n",
    "\"\"\"\n",
    "col: list[str] = ['Num_Acc', 'catv']\n",
    "\n",
    "\n",
    "# convert .csv file to pandas dataframe\n",
    "df: pd.DataFrame = pd.read_csv(vehicles_url, sep=';', usecols=col, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque le fichier Véhicules donne pour chaque accident un numéro de categorie de véhicule (*catv*), nous pouvons donc extraire depuis ce fichier les numéro d'accident unique des véhicules qui nous concernent seulement.  \n",
    "  \n",
    "En l'occurence seuls deux catégories référencés dans le descriptif nous concernent: les bicyclettes (01) et les VAE (80)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels: list[str] = [1, 80]\n",
    "\n",
    "# filter the dataframe to bycicles only\n",
    "df.query(\"catv == @labels\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous épurons enfin le résultat en retirant du dataset les colonnes nous ayant permis de faire le filtre précédent et en supprimant les duplicatas (un accident pouvant impliquer plus d'un véhicules)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then remove all columns but the accident id column\n",
    "df = df.filter(items=['Num_Acc'])\n",
    "# remove the duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtennons au final la liste complète des accidents impliquants un vélo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally print result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CONCLUSION\n",
    "Nous obtennons donc la liste complètes des accidents impliquants des vélos avec leur numéro d'accident.\n",
    "Nous n'avons plus qu'à explorer les données correspondantes à ces numéros pour pouvoir faire notre *data visualization*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
