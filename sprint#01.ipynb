{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Data University - Accidentologie à vélo\n",
    "\n",
    "Dans le cadre de l'opportunité Open Data University offert par *Latitudes*, nous nous sommes proposés pour un projet de *data visualization* autour de la problematiques de l'accidentologie à vélo pour apporté notre pierre à l'édifice parmis les grandes restructuration de la mobilité en France.  \n",
    "\n",
    "## SPRINT 01 - DATA CLEANING\n",
    "\n",
    "Qui dit *data visualization* dit *data*.  \n",
    "Nous avons donc trouver après recherche sur *www.data.gouv.fr* [les bases de données annuelles des accidents corporels de la circulation routière](https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2021/), un ensemble de données qui donne notamment les accidents en vélo et en VAE (Vélo à Assistance Electrique). Cependant le dataset couvre un scope plus grand que notre sujet puisqu'il se porte sur l'intégralité des accidents de la circulation routière. Il nous faut donc tout d'abord procéder à un nettoyage de la donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de 2005, la notation des accidents est séparée entre 4 fichiers: Caractéristiques, Lieux, Véhicules, Usagers.  \n",
    "Et C'est à partir du fichier Véhicules que nous allons donc pouvoir sélectionner les accidents impliquant seulement des vélo ou VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/guilhem/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/guilhem/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/guilhem/.local/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas to download, read and filter .csv files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the filepath to the .json file that contains all the dataset urls\n",
    "url_fp: str = \"data/metadata/urls.json\"\n",
    "\n",
    "# convert metadata file to dataframe which\n",
    "url_df: pd.DataFrame = pd.read_json(url_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On télécharge depuis les urls le fichier qui donne les caractéristiques des véhicules dans les accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_url(year: int, category: str) -> str | None:\n",
    "    valid_categories: list[str] = ['caractéristiques', 'lieux', 'véhicules', 'usagers']\n",
    "    valid_years: list[int]= [2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "    if year not in valid_years or category not in valid_categories:\n",
    "        return\n",
    "    \n",
    "    # Get year idx as year are in descendant order in metadata file\n",
    "    year_idx: int = 2021 - year\n",
    "    return url_df.at[year_idx, category]\n",
    "\n",
    "v_url: str | None = get_base_url(2021, 'véhicules')\n",
    "if v_url == None:\n",
    "    exit(0)\n",
    "\n",
    "\"\"\"\n",
    "    Only use those columns because\n",
    "    we only want to extract the accident id from the vehicule category\n",
    "\"\"\"\n",
    "v_col: list[str] = ['Num_Acc', 'catv']\n",
    "\n",
    "# convert .csv file to pandas dataframe\n",
    "v_df: pd.DataFrame = pd.read_csv(v_url, sep=';', usecols=v_col, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque le fichier Véhicules donne pour chaque accident un numéro de categorie de véhicule (*catv*), nous pouvons donc extraire depuis ce fichier les numéro d'accident unique des véhicules qui nous concernent seulement.  \n",
    "  \n",
    "En l'occurence seuls deux catégories référencés dans le descriptif nous concernent: les bicyclettes (01) et les VAE (80)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels: list[str] = [1, 80]\n",
    "\n",
    "# filter the dataframe to bycicles only\n",
    "v_df.query(\"catv == @labels\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous épurons enfin le résultat en retirant du dataset les colonnes nous ayant permis de faire le filtre précédent et en supprimant les duplicatas (un accident pouvant impliquer plus d'un véhicules)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then remove all columns but the accident id column\n",
    "v_df = v_df.filter(items=['Num_Acc'])\n",
    "# remove the duplicates\n",
    "v_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtennons au final la liste complète des accidents impliquants un vélo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Num_Acc\n",
      "0      202100000001\n",
      "9      202100000006\n",
      "63     202100000038\n",
      "92     202100000051\n",
      "120    202100000070\n",
      "...             ...\n",
      "97018  202100056346\n",
      "97041  202100056362\n",
      "97119  202100056404\n",
      "97159  202100056424\n",
      "97298  202100056508\n",
      "\n",
      "[5851 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Finally print result\n",
    "print(v_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CONCLUSION\n",
    "Nous obtennons donc la liste complètes des accidents impliquants des vélos avec leur numéro d'accident.\n",
    "Nous n'avons plus qu'à explorer les données correspondantes à ces numéros pour pouvoir faire notre *data visualization*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_url: str | None = get_base_url(year=2021, category='caractéristiques')\n",
    "if c_url == None:\n",
    "    exit(0)\n",
    "\n",
    "\"\"\"\n",
    "    Only use those columns because\n",
    "    we only want to extract the accident id from the vehicule category\n",
    "\"\"\"\n",
    "c_col: list[str] = ['Num_Acc', 'lat', 'long']\n",
    "\n",
    "# convert .csv file to pandas dataframe\n",
    "c_df: pd.DataFrame = pd.read_csv(c_url, sep=';', usecols=c_col, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycle_acc_loc_df: pd.DataFrame = pd.merge(v_df, c_df, on=['Num_Acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lat            long\n",
      "0     44,0389580000    4,3480220000\n",
      "1     47,6142390000    7,2343360000\n",
      "2     46,7668890000    4,4566240000\n",
      "3     43,6074900000    1,4281200000\n",
      "4     49,4262285502    2,0853413343\n",
      "...             ...             ...\n",
      "5846  48,8104900000    2,3619400000\n",
      "5847  43,2309460000   -0,2765840000\n",
      "5848  48,6849869839    6,1760189384\n",
      "5849  48,8769050000    2,3665940000\n",
      "5850  43,1465730000   -0,1955440000\n",
      "\n",
      "[5851 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "bicycle_acc_loc_df.drop(['Num_Acc'], axis=1, inplace=True)\n",
    "print(bicycle_acc_loc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycle_acc_loc_df.to_csv('bicycle_accidents.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
